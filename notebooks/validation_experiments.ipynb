{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACE Neural Validation Experiments (In-Silico)\n",
    "\n",
    "#### Dhuvarakesh Karthikeyan and Jin Seok (Andy) Lee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "from acelib.elispot import ELISpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive examples: 2297\n",
      "Number of negative examples: 4760\n"
     ]
    }
   ],
   "source": [
    "all_df = pd.read_csv('val_refs/iedb_mmer_all.csv')\n",
    "pos_df = all_df[all_df['Binding']==1].reset_index(drop=True)\n",
    "neg_df = all_df[all_df['Binding']==0].reset_index(drop=True)\n",
    "\n",
    "print(f'Number of positive examples: {len(pos_df)}')\n",
    "print(f'Number of negative examples: {len(neg_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AceSimulatedExperiment:\n",
    "    \"\"\"\n",
    "    Class to simulate an ELISPOT experiment with optimal peptide pools.\n",
    "\n",
    "    Experiment procedure:\n",
    "    1. Initialize objecty\n",
    "    2. Load reference CSV\n",
    "    3. Get optimized config\n",
    "    4. Simulate ELISPOT assay\n",
    "    5. Calculate sensitivity and specificity\n",
    "    \"\"\"\n",
    "    def __init__(self, num_peptides, num_positives, peptides_per_pool, coverage, disallowed_peptides=False, enforced_peptides=True,\n",
    "                 sliding_window_sample=False, deterministic=False, dispersion_factor=1, num_processes=8, random_seed=70203):\n",
    "        # Define the pooled ELISPOT parameters\n",
    "        self.num_peptides = num_peptides\n",
    "        self.num_positives = num_positives\n",
    "        self.peptides_per_pool = peptides_per_pool\n",
    "        self.coverage = coverage\n",
    "\n",
    "        # Define ACE parameters\n",
    "        self.disallowed_peptides = disallowed_peptides\n",
    "        self.enforced_peptides = enforced_peptides\n",
    "        if self.disallowed_peptides:\n",
    "            self.enforced_peptides = False\n",
    "        \n",
    "        # Define the simulation parameters\n",
    "        self.sliding_window_sample = sliding_window_sample\n",
    "        self.deterministic = deterministic\n",
    "        self.dispersion_factor = dispersion_factor\n",
    "        self.num_processes = num_processes\n",
    "        self.random_state = random_seed\n",
    "    \n",
    "    def load_reference_csv(self, path):\n",
    "        \"\"\"\n",
    "        Load the reference immunogenicity data from a csv format.\n",
    "        At minimum this data should have peptide, MHC allele, and \n",
    "        whether or not the pMHC complex is immunogenic.\n",
    "\n",
    "        Expected Columnn Names for the CSV:\n",
    "            - Epitope: The peptide sequences, all capital letters\n",
    "            - Allele: The MHC allele: HLA-[A,B,C]*[0-9][0-9]:[0-9][0-9]\n",
    "            - Binding: 1 if the pMHC was shown to be immunogenic, 0 otherwise\n",
    "        \"\"\"\n",
    "        assert os.path.exists(path), f'File does not exist: {path}'\n",
    "        data_df = pd.read_csv(path)\n",
    "        assert 'Epitope' in data_df.columns, f'Epitope column not found in {path}'\n",
    "        assert 'Binding' in data_df.columns, f'Binding column not found in {path}'\n",
    "        data_df.sort_values(by=['Epitope'], inplace=True)\n",
    "        self.data = data_df\n",
    "\n",
    "    def __run__(self):\n",
    "        \"\"\"\n",
    "        Run one iteration of the simulation.\n",
    "        \"\"\"\n",
    "        # Sample the peptides\n",
    "        peptide_ids, peptide_sequences, labels, disallowed_peptide_pairs, enforced_peptide_pairs = self.sample_peptides()\n",
    "        \n",
    "        # Run ACE to get the optimal configuration\n",
    "        assay, config_df = self.compute_optimized_config(peptide_ids, peptide_sequences, disallowed_peptide_pairs, enforced_peptide_pairs)\n",
    "        \n",
    "        # Simulate the ELISPOT assay\n",
    "        res_df = self.simulate_spot_counts(assay, config_df, peptide_ids, labels)\n",
    "\n",
    "        #hits = res_df[res_df['deconvolution_result']=='hit']['peptide_id'].values\n",
    "        hits = res_df['peptide_id'].values\n",
    "\n",
    "        positive_peptide_ids = [f'peptide_{i}' for i in range(len(peptide_ids)) if labels[i]==1]\n",
    "        negative_peptide_ids = [f'peptide_{i}' for i in range(len(peptide_ids)) if labels[i]==0]\n",
    "\n",
    "        # Calculate the sensitivity and specificity\n",
    "        sensitivity = len(set(hits).intersection(set(positive_peptide_ids)))/len(positive_peptide_ids)\n",
    "        specificity = len(set(hits).intersection(set(positive_peptide_ids)))/len(hits)\n",
    "\n",
    "        #print(f'Number of positive peptides: {len(positive_peptide_ids)}')\n",
    "        #print(f'Number of identified peptides: {len(hits)}')\n",
    "\n",
    "\n",
    "        res_df['Label'] = [1 if id in positive_peptide_ids else 0 for id in res_df['peptide_id']]\n",
    "        return res_df, sensitivity, specificity\n",
    "        \n",
    "    def run(self, num_iterations=1):\n",
    "        sensitivities = []\n",
    "        specificities = []\n",
    "        for _ in range(num_iterations):\n",
    "            res_df, sensitivity, specificity = self.__run__()\n",
    "            sensitivities.append(sensitivity)\n",
    "            specificities.append(specificity)\n",
    "        if num_iterations == 1:\n",
    "            print(f'Sensitivity: {sensitivity}')\n",
    "            print(f'Specificity: {specificity}')\n",
    "            return res_df\n",
    "        return sensitivities, specificities\n",
    "\n",
    "    def sample_peptides(self):\n",
    "        \"\"\"\n",
    "        Sample the peptide sequences and their immunogenicity status\n",
    "        from the reference data.\n",
    "\n",
    "        NOTE: We do this instead of randomly initializing peptide sequences\n",
    "        because the ACE Neural Engine was trained on real sequence data. Thus,\n",
    "        to make meaningful disallowed peptide pairings we utilize a reference\n",
    "        dataset.\n",
    "        \"\"\"\n",
    "        # Sample the peptides\n",
    "        pos_df = self.data[self.data['Binding']==1].reset_index(drop=True)\n",
    "        neg_df = self.data[self.data['Binding']==0].reset_index(drop=True)\n",
    "\n",
    "        if self.sliding_window_sample:\n",
    "            pos_idx = np.random.randint(0, len(pos_df)-self.num_positives)\n",
    "            neg_idx = np.random.randint(0, len(neg_df)-(self.num_peptides))\n",
    "            # Pick peptides that are close to each other\n",
    "            positive_peptides = self.data[self.data['Binding']==1].iloc[pos_idx:pos_idx+self.num_positives]\n",
    "            negative_peptides = self.data[self.data['Binding']==0].iloc[neg_idx:(neg_idx+self.num_peptides-self.num_positives)]\n",
    "        else:\n",
    "            positive_peptides = self.data[self.data['Binding']==1].sample(self.num_positives)\n",
    "            negative_peptides = self.data[self.data['Binding']==0].sample(self.num_peptides-self.num_positives)\n",
    "        \n",
    "        # Combine the peptides and shuffle them\n",
    "        peptides = pd.concat([positive_peptides, negative_peptides]).sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "        #############################\n",
    "        ### Temporary for testing ###\n",
    "        #############################\n",
    "        # to be replaced by bonafide sequence similarity\n",
    "        positives = peptides[peptides['Binding']==1]\n",
    "        disallowed_peptide_pairs = []\n",
    "        enforced_peptide_pairs = []\n",
    "        if self.disallowed_peptides:\n",
    "            for idx, _ in positives.iterrows():\n",
    "                for idx2, _ in positives.iterrows():\n",
    "                    if idx != idx2:\n",
    "                        disallowed_peptide_pairs.append((f'peptide_{idx}', f'peptide_{idx2}'))\n",
    "        if self.enforced_peptides:\n",
    "            enforced_peptide_pairs = []\n",
    "            for idx, _ in positives.iterrows():\n",
    "                for idx2, _ in positives.iterrows():\n",
    "                    if idx != idx2:\n",
    "                        enforced_peptide_pairs.append((f'peptide_{idx}', f'peptide_{idx2}'))\n",
    "        #############################\n",
    "        #############################\n",
    "        \n",
    "        peptide_ids = [f'peptide_{idx}' for idx in peptides.index.values]\n",
    "        peptide_sequences = peptides['Epitope'].values\n",
    "        labels = peptides['Binding'].values\n",
    "        return peptide_ids, peptide_sequences, labels, disallowed_peptide_pairs, enforced_peptide_pairs\n",
    "\n",
    "    def compute_optimized_config(self, peptide_ids, peptide_sequences, disallowed_peptide_pairs, enforced_peptide_pairs):\n",
    "        \"\"\"\n",
    "        Run ACE to generate the optimal peptide pools.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create the ELISPOT assay object\n",
    "        assay = ELISpot(\n",
    "            num_peptides_per_pool=self.peptides_per_pool,\n",
    "            num_coverage=self.coverage,\n",
    "            num_processes=10,\n",
    "            peptide_ids=peptide_ids,\n",
    "            peptide_sequences=peptide_sequences\n",
    "        )\n",
    "\n",
    "        # Generate the configuration using the optimization algorithm\n",
    "        generation_status, config_df = assay.generate_configuration(disallowed_peptide_pairs=disallowed_peptide_pairs, random_seed=self.random_state)\n",
    "        try:\n",
    "            assert len(config_df) > 0\n",
    "        except:\n",
    "            raise AssertionError(f'No valid configurations found for the assay parameters. Please try again with different parameters.')\n",
    "        return assay, config_df\n",
    "    \n",
    "    @staticmethod\n",
    "    def sample_spot_counts(mean: float, dispersion_factor, num_samples):\n",
    "        \"\"\"\n",
    "        Sample the number of spots for a peptide pool using a negative binomial distribution.\n",
    "\n",
    "        Derivation of NegBinom Parameters:\n",
    "\n",
    "            Let X be the number RV of spots sampled for a peptide pool.\n",
    "            Let p be the probability of sampling a spot for a peptide in the pool.\n",
    "            Let r be the number of successes (spots) we want to sample.\n",
    "            Let k be the number of failures (non-spots) we want to sample.\n",
    "\n",
    "            Then, the probability mass function for X is given by:\n",
    "\n",
    "            P(X=k) = (k+r-1)C(k) * p^r * (1-p)^k\n",
    "            \n",
    "            where (k+r-1)C(k) is the binomial coefficient.\n",
    "\n",
    "            The mean and variance of X are given by:\n",
    "\n",
    "            mean = r(1-p)/p\n",
    "            var = r(1-p)/p^2\n",
    "\n",
    "            We can solve for p and r in terms of the mean and variance:\n",
    "\n",
    "            p = mean / var\n",
    "            r = mean^2 / (var - mean)\n",
    "        \"\"\"\n",
    "        if dispersion_factor < 1:\n",
    "            raise ValueError(\"dispersion_factor must be greater than or equal to 1\")\n",
    "        elif dispersion_factor == 1:\n",
    "            return np.random.poisson(mean, num_samples)\n",
    "        else:    \n",
    "            variance = mean*dispersion_factor\n",
    "            p = mean/variance\n",
    "            r = mean**2/(variance-mean)\n",
    "            return np.random.negative_binomial(r, p, num_samples)\n",
    "\n",
    "    def simulate_spot_counts(self, assay, config_df, peptide_ids, labels):\n",
    "        \"\"\"\n",
    "        Simulate the ELISPOT assay using the optimal peptide pools configuration.\n",
    "        Determine how spots are sampled for each peptide pool. \n",
    "\n",
    "        Assumptions:\n",
    "            1. The number of spots sampled for each peptide pool follows a negative binomial distribution.\n",
    "            2. The number of spots sampled for each peptide pool is independent of the other peptide pools.\n",
    "            3. Immunogenic and non-immunogenic peptides have the same shape parameters for the negative binomial distribution, \n",
    "            but different mean parameters. This is because we assume the experimental error/noise is the same for both whereas\n",
    "            true immunogenic peptides will likely have more spots than non-immunogenic peptides.\n",
    "            4. We assume that having multiple immunogenic peptides in a pool addiditively increases the number of spots sampled\n",
    "\n",
    "\n",
    "        Parameters:\n",
    "            config_df: The optimal peptide pools configuration dataframe\n",
    "            peptide_ids: The peptide ids for each peptide sequence\n",
    "            labels: The immunogenicity labels for each peptide sequence\n",
    "\n",
    "        Returns:\n",
    "            hit_pool_list: A list of the pool ids that were determined to be hits\n",
    "        \"\"\"\n",
    "        label_dict = {peptide_id:label for peptide_id, label in zip(peptide_ids, labels)}\n",
    "        hit_pool_list = []\n",
    "        # In the deterministic case we just use the labels to get 0/1 spot counts\n",
    "        if self.deterministic:\n",
    "            # Check to see if that pool has an immunogenic peptide in it\n",
    "            for pool_id in config_df['pool_id'].unique():\n",
    "                pool_df = config_df[config_df['pool_id']==pool_id]\n",
    "                for peptide_id in pool_df['peptide_id']:\n",
    "                    if label_dict[peptide_id] == 1:\n",
    "                        hit_pool_list.append(pool_id)\n",
    "                        break\n",
    "\n",
    "        # Simulate according to a probabilistic model\n",
    "        else:\n",
    "            immunogenic_mean = 100\n",
    "            non_immunogenic_mean = 10\n",
    "            \n",
    "            pool_spot_counts = {i:0 for i in config_df['pool_id'].unique()}\n",
    "            for pool_id in config_df['pool_id'].unique():\n",
    "                pool_df = config_df[config_df['pool_id']==pool_id]\n",
    "                for peptide_id in pool_df['peptide_id']:\n",
    "                    if label_dict[peptide_id] == 1:\n",
    "                        pool_spot_counts[pool_id] += AceSimulatedExperiment.sample_spot_counts(immunogenic_mean, self.dispersion_factor, num_samples=1)[0]\n",
    "                    else:\n",
    "                        pool_spot_counts[pool_id] += AceSimulatedExperiment.sample_spot_counts(non_immunogenic_mean, self.dispersion_factor, num_samples=1)[0]\n",
    "                    # Check to see if we have enough spots to call it a hit\n",
    "                    if pool_spot_counts[pool_id] >= immunogenic_mean:\n",
    "                            hit_pool_list.append(pool_id)\n",
    "                            break    \n",
    "        \n",
    "        res_df = assay.identify_hit_peptides(hit_pool_list, config_df)\n",
    "        return res_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 18:56:59 INFO     CP solver started.\n",
      "2023-07-03 18:56:59 INFO     CP solver finished.\n",
      "2023-07-03 18:56:59 INFO     An optimal feasible solution was found.\n",
      "2023-07-03 18:56:59 INFO     CP solver started.\n",
      "2023-07-03 18:57:00 INFO     CP solver finished.\n",
      "2023-07-03 18:57:00 INFO     An optimal feasible solution was found.\n",
      "2023-07-03 18:57:00 INFO     CP solver started.\n",
      "2023-07-03 18:57:00 INFO     CP solver finished.\n",
      "2023-07-03 18:57:00 INFO     An optimal feasible solution was found.\n",
      "2023-07-03 18:57:00 INFO     CP solver started.\n",
      "2023-07-03 18:57:00 INFO     CP solver finished.\n",
      "2023-07-03 18:57:00 INFO     An optimal feasible solution was found.\n",
      "2023-07-03 18:57:00 INFO     CP solver started.\n",
      "2023-07-03 18:57:01 INFO     CP solver finished.\n",
      "2023-07-03 18:57:01 INFO     An optimal feasible solution was found.\n",
      "2023-07-03 18:57:01 INFO     CP solver started.\n",
      "2023-07-03 18:57:01 INFO     CP solver finished.\n",
      "2023-07-03 18:57:01 INFO     An optimal feasible solution was found.\n",
      "2023-07-03 18:57:01 INFO     CP solver started.\n",
      "2023-07-03 18:57:01 INFO     CP solver finished.\n",
      "2023-07-03 18:57:01 INFO     An optimal feasible solution was found.\n",
      "2023-07-03 18:57:02 INFO     CP solver started.\n",
      "2023-07-03 18:57:02 INFO     CP solver finished.\n",
      "2023-07-03 18:57:02 INFO     An optimal feasible solution was found.\n",
      "2023-07-03 18:57:02 INFO     CP solver started.\n",
      "2023-07-03 18:57:02 INFO     CP solver finished.\n",
      "2023-07-03 18:57:02 INFO     An optimal feasible solution was found.\n",
      "2023-07-03 18:57:02 INFO     CP solver started.\n",
      "2023-07-03 18:57:03 INFO     CP solver finished.\n",
      "2023-07-03 18:57:03 INFO     An optimal feasible solution was found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8, 1.0, 0.8, 0.8400000000000001, 0.07999999999999999)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation = AceSimulatedExperiment(\n",
    "                                    num_peptides=20,\n",
    "                                    num_positives=5,\n",
    "                                    peptides_per_pool=3,\n",
    "                                    coverage=3,\n",
    "                                    disallowed_peptides=False,\n",
    "                                    enforced_peptides=True,\n",
    "                                    sliding_window_sample=False,\n",
    "                                    deterministic=False,\n",
    "                                    dispersion_factor=2,\n",
    "                                    num_processes=8\n",
    "                                )\n",
    "simulation.load_reference_csv('val_refs/iedb_mmer_all.csv')\n",
    "sensitivities, specificities = simulation.run(10)\n",
    "\n",
    "min(sensitivities), max(sensitivities), np.median(sensitivities), np.mean(sensitivities), np.std(sensitivities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation = AceSimulatedExperiment(\n",
    "                                    num_peptides=20,\n",
    "                                    num_positives=5,\n",
    "                                    peptides_per_pool=3,\n",
    "                                    coverage=3,\n",
    "                                    disallowed_peptides=False,\n",
    "                                    enforced_peptides=True,\n",
    "                                    sliding_window_sample=False,\n",
    "                                    deterministic=False,\n",
    "                                    dispersion_factor=2,\n",
    "                                    num_processes=8\n",
    "                                )\n",
    "simulation.load_reference_csv('val_refs/iedb_mmer_all.csv')\n",
    "sensitivities, specificities = simulation.run(10)\n",
    "\n",
    "min(sensitivities), max(sensitivities), np.median(sensitivities), np.mean(sensitivities), np.std(sensitivities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_peptide_list_rough(data_df, num_samples, num_positives):\n",
    "    \"\"\"\n",
    "    Samples a list of peptides from a dataframe of peptides.\n",
    "\n",
    "    Returns a dataframe of num_samples peptides, with num_positives\n",
    "    positive peptides (immunogenic)\n",
    "    \"\"\"\n",
    "    # Sample num_positives positive peptides\n",
    "    pos_df = data_df[data_df['Binding']==1].reset_index(drop=True)\n",
    "    assert num_positives <= len(pos_df), 'num_positives must be less than or equal to the number of positive peptides in the dataframe'\n",
    "    pos_sample = pos_df.sample(n=num_positives, replace=False)\n",
    "    \n",
    "    # Sample num_samples - num_positives negative peptides\n",
    "    neg_df = data_df[data_df['Binding']==0].reset_index(drop=True)\n",
    "    assert num_samples - num_positives <= len(neg_df), 'num_samples - num_positives must be less than or equal to the number of negative peptides in the dataframe'\n",
    "    neg_sample = neg_df.sample(n=num_samples - num_positives)\n",
    "    \n",
    "    # Combine the two samples\n",
    "    sample_df = pd.concat([pos_sample, neg_sample]).reset_index(drop=True)\n",
    "    \n",
    "    return sample_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['peptide_1', 'peptide_10', 'peptide_100']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(['peptide_1', 'peptide_10', 'peptide_100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HLA-A*02:01    32\n",
       "HLA-B*07:02    15\n",
       "HLA-A*11:01     8\n",
       "HLA-A*24:02     6\n",
       "HLA-A*03:01     6\n",
       "HLA-B*51:01     5\n",
       "HLA-B*35:01     5\n",
       "HLA-C*04:01     4\n",
       "HLA-C*07:01     4\n",
       "HLA-B*18:01     3\n",
       "HLA-B*58:01     2\n",
       "HLA-B*15:01     2\n",
       "HLA-A*68:01     1\n",
       "HLA-B*57:01     1\n",
       "HLA-C*05:01     1\n",
       "HLA-A*32:01     1\n",
       "HLA-B*27:05     1\n",
       "HLA-B*40:01     1\n",
       "HLA-B*35:08     1\n",
       "HLA-B*44:03     1\n",
       "Name: Allele Name, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_peptide_list_rough(temp_df, 100, 5)['Allele Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_peptide_list(data_df, n=10, weighted=True, haplotype=True):\n",
    "    \"\"\"\n",
    "    Sample a potential ELISPOT List of peptides from a dataframe\n",
    "    of in-vitro or otherwise validated peptides. Current support\n",
    "    only includes MHC-I and human data. Expanding to MHC-II and\n",
    "    mouse soon.\n",
    "\n",
    "    Args:\n",
    "        data_df (pd.DataFrame): Dataframe of Eptiope:MHC:Binding data\n",
    "        n (int): Number of peptides to sample from each allele\n",
    "        weighted (bool): Whether to weight the sampling by dset prevalence\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe of sampled peptides\n",
    "    \"\"\"\n",
    "    if weighted:\n",
    "        # Weighted according to prevalence in the dataset\n",
    "        alleles = data_df['Allele Name']\n",
    "    else:\n",
    "        # Unweighted, chosen from uniform across all alleles\n",
    "        alleles = data_df['Allele Name'].unique()\n",
    "    \n",
    "    if haplotype:\n",
    "        # Split alleles into HLA-A, HLA-B, HLA-C\n",
    "        hla_a = [a for a in alleles if 'HLA-A' in a]\n",
    "        hla_b = [b for b in alleles if 'HLA-B' in b]\n",
    "        hla_c = [c for c in alleles if 'HLA-C' in c]\n",
    "\n",
    "        # Grab 2 random alleles from each HLA-A, HLA-B, HLA-C\n",
    "        # Represents one from mom and one for dad\n",
    "        hla_a_sample = np.random.choice(hla_a, 2, replace=True)\n",
    "        hla_b_sample = np.random.choice(hla_b, 2, replace=True)\n",
    "        hla_c_sample = np.random.choice(hla_c, 2, replace=True)\n",
    "        alleles = np.concatenate([hla_a_sample, hla_b_sample, hla_c_sample])\n",
    "        \n",
    "    # Subset the dataframe to only include the sampled alleles\n",
    "    sampled_df = data_df[data_df['Allele Name'].isin(alleles)]\n",
    "\n",
    "    # Sample n peptides from each allele    \n",
    "    counts = sampled_df.groupby(['Allele Name']).count()\n",
    "    return_df = pd.DataFrame()\n",
    "    for allele in counts.index:\n",
    "        if counts.loc[allele, 'Epitope'] <= n:\n",
    "            return_df = pd.concat([return_df, sampled_df[sampled_df['Allele Name'] == allele]])\n",
    "        else:\n",
    "            return_df = pd.concat([return_df, sampled_df[sampled_df['Allele Name'] == allele].sample(n=n, replace=False)])\n",
    "            \n",
    "    return_df = return_df.reset_index(drop=True)\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = sample_peptide_list(temp_df, n=25, haplotype=True).sample(25, replace=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epitope</th>\n",
       "      <th>Allele Name</th>\n",
       "      <th>Binding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMQSYTWSL</td>\n",
       "      <td>HLA-C*04:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEDSRDEHRKL</td>\n",
       "      <td>HLA-C*04:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GMPPHMLPVL</td>\n",
       "      <td>HLA-C*04:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TPVTPRWPEV</td>\n",
       "      <td>HLA-B*07:02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RLSTASFPT</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LPTVKLAEV</td>\n",
       "      <td>HLA-B*07:02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FPQLTTRRL</td>\n",
       "      <td>HLA-B*07:02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>YPRMDIPKI</td>\n",
       "      <td>HLA-B*07:02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VMPFSIVYIV</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KVSWAAVTLLL</td>\n",
       "      <td>HLA-C*04:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>YPFHDIEPSSL</td>\n",
       "      <td>HLA-B*35:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FFLVTYMAPL</td>\n",
       "      <td>HLA-C*04:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HPFALLLVL</td>\n",
       "      <td>HLA-B*35:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HPVGQADYFEY</td>\n",
       "      <td>HLA-B*35:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HPLMFKSTAK</td>\n",
       "      <td>HLA-B*07:02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>YLHPKEYEWVL</td>\n",
       "      <td>HLA-C*04:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AIYDTMQYV</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SPVPQGARWRL</td>\n",
       "      <td>HLA-B*07:02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SLYNLVATL</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>YVMASVFVCPL</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FHPPPTSLIFL</td>\n",
       "      <td>HLA-C*04:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MMWDRGLGMM</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RPYPLIYFL</td>\n",
       "      <td>HLA-C*04:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVWGSSRWL</td>\n",
       "      <td>HLA-C*04:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KPANNSLKI</td>\n",
       "      <td>HLA-B*07:02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Epitope  Allele Name  Binding\n",
       "0     AMQSYTWSL  HLA-C*04:01        0\n",
       "1   MEDSRDEHRKL  HLA-C*04:01        0\n",
       "2    GMPPHMLPVL  HLA-C*04:01        0\n",
       "3    TPVTPRWPEV  HLA-B*07:02        0\n",
       "4     RLSTASFPT  HLA-A*02:01        0\n",
       "5     LPTVKLAEV  HLA-B*07:02        0\n",
       "6     FPQLTTRRL  HLA-B*07:02        1\n",
       "7     YPRMDIPKI  HLA-B*07:02        1\n",
       "8    VMPFSIVYIV  HLA-A*02:01        1\n",
       "9   KVSWAAVTLLL  HLA-C*04:01        0\n",
       "10  YPFHDIEPSSL  HLA-B*35:01        1\n",
       "11   FFLVTYMAPL  HLA-C*04:01        0\n",
       "12    HPFALLLVL  HLA-B*35:01        1\n",
       "13  HPVGQADYFEY  HLA-B*35:01        1\n",
       "14   HPLMFKSTAK  HLA-B*07:02        0\n",
       "15  YLHPKEYEWVL  HLA-C*04:01        0\n",
       "16    AIYDTMQYV  HLA-A*02:01        0\n",
       "17  SPVPQGARWRL  HLA-B*07:02        0\n",
       "18    SLYNLVATL  HLA-A*02:01        1\n",
       "19  YVMASVFVCPL  HLA-A*02:01        0\n",
       "20  FHPPPTSLIFL  HLA-C*04:01        0\n",
       "21   MMWDRGLGMM  HLA-A*02:01        1\n",
       "22    RPYPLIYFL  HLA-C*04:01        0\n",
       "23    SVWGSSRWL  HLA-C*04:01        0\n",
       "24    KPANNSLKI  HLA-B*07:02        0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "2023-06-28 15:46:41 INFO     CP solver started.\n",
      "2023-06-28 15:46:42 INFO     CP solver finished.\n",
      "2023-06-28 15:46:42 INFO     Solution is optimal.\n",
      "2023-06-28 15:46:42 INFO     An optimal configuration has been generated.\n"
     ]
    }
   ],
   "source": [
    "! ace generate --num-peptides 25 --num-peptides-per-pool 5 --num-coverage 3 --num-processes 10 --output-csv output_csv.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pool_id</th>\n",
       "      <th>peptide_id</th>\n",
       "      <th>plate_id</th>\n",
       "      <th>well_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pool_2</td>\n",
       "      <td>peptide_25</td>\n",
       "      <td>1</td>\n",
       "      <td>A8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>pool_7</td>\n",
       "      <td>peptide_25</td>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>pool_12</td>\n",
       "      <td>peptide_25</td>\n",
       "      <td>1</td>\n",
       "      <td>A4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pool_id  peptide_id  plate_id well_id\n",
       "9    pool_2  peptide_25         1      A8\n",
       "34   pool_7  peptide_25         1      B1\n",
       "59  pool_12  peptide_25         1      A4"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ace_config = pd.read_csv('output_csv.csv')\n",
    "ace_config[ace_config['peptide_id']=='peptide_25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17207/4066224591.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mace_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mace_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pool_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'pool_2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pool_4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pool_13'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Dissertation/Projects/Active/ace/venv/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1527\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1528\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "ace_config[ace_config['pool_id'] in ['pool_2', 'pool_4', 'pool_13']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_ace_readout(ace_config, ground_truth_df):\n",
    "    \"\"\"\n",
    "    Simulate the readout of an ACE experiment, given a configuration,\n",
    "    the ground truth values of the peptides.\n",
    "    \"\"\"\n",
    "    ace_results = ace_config.copy()\n",
    "    for index in ground_truth_df.index:\n",
    "        peptide_id = f'peptide_{index+1}'\n",
    "        binding = ground_truth_df.loc[index, 'Binding']\n",
    "        ace_results.loc[ace_results['peptide_id']==peptide_id, 'Binding'] = binding\n",
    "\n",
    "    print(ace_results[ace_results['Binding']==1])\n",
    "    for pool_id in ace_results['pool_id'].unique():\n",
    "        pool_df = ace_results[ace_results['pool_id']==pool_id]\n",
    "        pool_binding = 1 if pool_df['Binding'].sum() > 0 else 0\n",
    "        ace_results.loc[ace_results['pool_id']==pool_id, 'spot_count'] = pool_binding\n",
    "    return ace_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pool_id  peptide_id  plate_id well_id  Binding\n",
      "1    pool_1   peptide_7         1      A1      1.0\n",
      "5    pool_2   peptide_1         1      A8      1.0\n",
      "9    pool_2  peptide_25         1      A8      1.0\n",
      "17   pool_4  peptide_14         1     A10      1.0\n",
      "27   pool_6  peptide_14         1     A12      1.0\n",
      "32   pool_7   peptide_7         1      B1      1.0\n",
      "34   pool_7  peptide_25         1      B1      1.0\n",
      "40   pool_9   peptide_1         1      B3      1.0\n",
      "51  pool_11  peptide_14         1      A3      1.0\n",
      "59  pool_12  peptide_25         1      A4      1.0\n",
      "60  pool_13   peptide_1         1      A5      1.0\n",
      "70  pool_15   peptide_7         1      A7      1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pool_id</th>\n",
       "      <th>peptide_id</th>\n",
       "      <th>plate_id</th>\n",
       "      <th>well_id</th>\n",
       "      <th>Binding</th>\n",
       "      <th>spot_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pool_1</td>\n",
       "      <td>peptide_5</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pool_1</td>\n",
       "      <td>peptide_7</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pool_1</td>\n",
       "      <td>peptide_8</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pool_1</td>\n",
       "      <td>peptide_19</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pool_1</td>\n",
       "      <td>peptide_20</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>pool_15</td>\n",
       "      <td>peptide_7</td>\n",
       "      <td>1</td>\n",
       "      <td>A7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>pool_15</td>\n",
       "      <td>peptide_9</td>\n",
       "      <td>1</td>\n",
       "      <td>A7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>pool_15</td>\n",
       "      <td>peptide_11</td>\n",
       "      <td>1</td>\n",
       "      <td>A7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>pool_15</td>\n",
       "      <td>peptide_12</td>\n",
       "      <td>1</td>\n",
       "      <td>A7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>pool_15</td>\n",
       "      <td>peptide_15</td>\n",
       "      <td>1</td>\n",
       "      <td>A7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pool_id  peptide_id  plate_id well_id  Binding  spot_count\n",
       "0    pool_1   peptide_5         1      A1      0.0         1.0\n",
       "1    pool_1   peptide_7         1      A1      1.0         1.0\n",
       "2    pool_1   peptide_8         1      A1      0.0         1.0\n",
       "3    pool_1  peptide_19         1      A1      0.0         1.0\n",
       "4    pool_1  peptide_20         1      A1      0.0         1.0\n",
       "..      ...         ...       ...     ...      ...         ...\n",
       "70  pool_15   peptide_7         1      A7      1.0         1.0\n",
       "71  pool_15   peptide_9         1      A7      0.0         1.0\n",
       "72  pool_15  peptide_11         1      A7      0.0         1.0\n",
       "73  pool_15  peptide_12         1      A7      0.0         1.0\n",
       "74  pool_15  peptide_15         1      A7      0.0         1.0\n",
       "\n",
       "[75 rows x 6 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_ace_readout(ace_config, sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pool_id</th>\n",
       "      <th>spot_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pool_1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pool_2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pool_3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pool_4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pool_5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pool_6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>pool_7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>pool_8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>pool_9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>pool_10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>pool_11</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>pool_12</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>pool_13</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>pool_14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>pool_15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pool_id  spot_count\n",
       "0    pool_1         1.0\n",
       "5    pool_2         1.0\n",
       "10   pool_3         0.0\n",
       "15   pool_4         1.0\n",
       "20   pool_5         0.0\n",
       "25   pool_6         1.0\n",
       "30   pool_7         1.0\n",
       "35   pool_8         0.0\n",
       "40   pool_9         1.0\n",
       "45  pool_10         0.0\n",
       "50  pool_11         1.0\n",
       "55  pool_12         1.0\n",
       "60  pool_13         1.0\n",
       "65  pool_14         0.0\n",
       "70  pool_15         1.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readout_df = simulate_ace_readout(ace_config, sample_df)\n",
    "readout_df = readout_df[['pool_id', 'spot_count']].drop_duplicates()  \n",
    "readout_df.to_csv('readout.csv', index=False)\n",
    "readout_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ace identify --readout-file-type pool_id --readout-files readout.csv --configuration-csv-file output_csv.csv --min-positive-spot-count 1 --output-csv identify_output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peptide_id</th>\n",
       "      <th>pool_ids</th>\n",
       "      <th>num_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>peptide_7</td>\n",
       "      <td>pool_1,pool_7,pool_15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>peptide_20</td>\n",
       "      <td>pool_1,pool_6,pool_12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>peptide_1</td>\n",
       "      <td>pool_2,pool_9,pool_13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>peptide_11</td>\n",
       "      <td>pool_2,pool_6,pool_15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>peptide_25</td>\n",
       "      <td>pool_2,pool_7,pool_12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>peptide_9</td>\n",
       "      <td>pool_4,pool_9,pool_15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>peptide_14</td>\n",
       "      <td>pool_4,pool_6,pool_11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    peptide_id               pool_ids  num_coverage\n",
       "1    peptide_7  pool_1,pool_7,pool_15             3\n",
       "4   peptide_20  pool_1,pool_6,pool_12             3\n",
       "5    peptide_1  pool_2,pool_9,pool_13             3\n",
       "6   peptide_11  pool_2,pool_6,pool_15             3\n",
       "9   peptide_25  pool_2,pool_7,pool_12             3\n",
       "11   peptide_9  pool_4,pool_9,pool_15             3\n",
       "12  peptide_14  pool_4,pool_6,pool_11             3"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identified_peptides = pd.read_csv('identify_output.csv')\n",
    "identified_peptides[identified_peptides['num_coverage'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     1,7,15\n",
       "4     1,6,12\n",
       "5     2,9,13\n",
       "6     2,6,15\n",
       "9     2,7,12\n",
       "11    4,9,15\n",
       "12    4,6,11\n",
       "Name: pool_ids, dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identified_peptides[identified_peptides['num_coverage'] == 3]['pool_ids'].apply(lambda x: re.sub(r'pool_', '', x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling the ELISPOT False Discovery Rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without Sequence Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randint() got an unexpected keyword argument 'with_replacement'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mrandint(\u001b[39m0\u001b[39;49m, \u001b[39m100\u001b[39;49m, \u001b[39m10\u001b[39;49m, with_replacement\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32mmtrand.pyx:646\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: randint() got an unexpected keyword argument 'with_replacement'"
     ]
    }
   ],
   "source": [
    "### Sample without replacement\n",
    "np.random.randint(0, 100, 10, dtype=np.int32, endpoint=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Sequence Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
